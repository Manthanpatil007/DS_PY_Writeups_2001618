{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOL/wu9ZerWZoXCFZluepjj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manthanpatil007/DS_PY_Writeups_2001618/blob/main/Exp08_notebook_2001618pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EXFnuusPxj_9",
        "outputId": "6406d9c7-7e46-4691-8c71-7da4974ef867"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.22.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "numpy.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/My_Drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeMatCiwxqUC",
        "outputId": "fd43dea6-6c22-48e2-b1ee-9424b65ec9a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/My_Drive; to attempt to forcibly remount, call drive.mount(\"/content/My_Drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Define your Problem statement and ML technique I(one) you propose to use. "
      ],
      "metadata": {
        "id": "UX2q9wT3Jd03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dry Bean Dataset contains features of 13,611 images of 7 different types of dry beans. The goal of this problem is to build a machine learning model that can accurately classify the type of dry bean based on the input image.\n",
        "\n",
        "For this problem, I propose to use Convolutional Neural Networks (CNNs) as the machine learning technique. CNNs are widely used for image classification problems and have shown to be very effective in achieving high accuracy. CNNs use a series of convolutional layers to extract features from the input images and learn representations of the data, which are then used to make predictions.\n",
        "\n",
        "The Dry Bean Dataset contains images of different sizes, and we need to resize them to a common size to feed them into the CNN. We can use data augmentation techniques such as rotation, flipping, and zooming to increase the size of the training dataset and improve the generalization of the model. We can also use transfer learning, which involves using pre-trained CNN models as a starting point and fine-tuning them on our specific dataset.\n",
        "\n",
        "In summary, the problem is to classify the type of dry bean based on input images using CNNs, and the proposed pre-processing steps include resizing the images, data augmentation, and possibly transfer learning."
      ],
      "metadata": {
        "id": "iGROOznPQ_AM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write about working of ML technique I you have proposed  "
      ],
      "metadata": {
        "id": "575g6CheJoug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 / 2\n",
        "\n",
        "Convolutional Neural Networks (CNNs) are a type of deep learning algorithm that are widely used for image classification, object detection, and segmentation tasks. CNNs are designed to automatically learn features and patterns in images, without the need for manual feature engineering.\n",
        "\n",
        "The basic building block of a CNN is the convolutional layer, which performs a series of convolutions on the input image using a set of learnable filters. Each filter is a small matrix of weights that is applied to the input image to extract a specific feature. During training, the CNN learns the optimal values for these filter weights that maximize the accuracy of the classification task.\n",
        "\n",
        "After the convolutional layer, the output is typically passed through a pooling layer, which reduces the spatial size of the feature maps by taking the maximum or average value in each sub-region. The pooling layer helps to reduce the number of parameters in the model and prevent overfitting.\n",
        "\n",
        "The output of the pooling layer is then passed through a series of fully connected layers, which learn to classify the input image into one of the pre-defined classes. The fully connected layers perform a series of matrix multiplications and apply non-linear activation functions to generate the final output."
      ],
      "metadata": {
        "id": "OPullN_XJpk2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Do pre-processing as per requirements of ML technique I "
      ],
      "metadata": {
        "id": "aRC7RtbIQj4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "df = pd.read_csv('/content/My_Drive/MyDrive/Classroom/Dry_Bean_Dataset.csv')\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['Class'] = le.fit_transform(df['Class'])\n",
        "\n",
        "\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "jFfYTd8DKkWm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Divide Data set in to training and validation sets\n",
        "\n"
      ],
      "metadata": {
        "id": "dOyccNRoSEYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"/content/My_Drive/MyDrive/Classroom/Dry_Bean_Dataset.csv\")\n",
        "\n",
        "\n",
        "X = data.drop(columns=[\"Class\"])\n",
        "y = data[\"Class\"]\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlXgx-hnSBNE",
        "outputId": "0fc9f41c-5d11-4886-e862-6dcbbbd59b1f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (10888, 16) (10888,)\n",
            "Validation set shape: (2723, 16) (2723,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Perform training "
      ],
      "metadata": {
        "id": "Ri-5qAcJSHQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"/content/My_Drive/MyDrive/Classroom/Dry_Bean_Dataset.csv\")\n",
        "\n",
        "\n",
        "X = data.drop(columns=[\"Class\"])\n",
        "y = data[\"Class\"]\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation set accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fETOkhuMSJr9",
        "outputId": "580b0e2f-69fb-47f6-874b-d47ebd7d210b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set accuracy: 0.6841718692618436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Perform Validation"
      ],
      "metadata": {
        "id": "e9yP1-02SM_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"/content/My_Drive/MyDrive/Classroom/Dry_Bean_Dataset.csv\")\n",
        "\n",
        "\n",
        "X = data.drop(columns=[\"Class\"])\n",
        "y = data[\"Class\"]\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "\n",
        "report = classification_report(y_val, y_pred)\n",
        "print(\"Validation set classification report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHTLsGUzSPqz",
        "outputId": "6ef3dd35-ac91-47a1-c039-0c27215f3e14"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    BARBUNYA       0.52      0.48      0.50       261\n",
            "      BOMBAY       0.99      1.00      1.00       117\n",
            "        CALI       0.71      0.69      0.70       317\n",
            "    DERMASON       0.79      0.84      0.81       671\n",
            "       HOROZ       0.61      0.65      0.63       408\n",
            "       SEKER       0.68      0.58      0.63       413\n",
            "        SIRA       0.60      0.62      0.61       536\n",
            "\n",
            "    accuracy                           0.68      2723\n",
            "   macro avg       0.70      0.69      0.70      2723\n",
            "weighted avg       0.68      0.68      0.68      2723\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Report Accuracy of your trained ML Model"
      ],
      "metadata": {
        "id": "4FMuq0EVTtU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"/content/My_Drive/MyDrive/Classroom/Dry_Bean_Dataset.csv\")\n",
        "\n",
        "\n",
        "X = data.drop(columns=[\"Class\"])\n",
        "y = data[\"Class\"]\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnrUQGMXThuz",
        "outputId": "46026f3d-c2aa-49c2-e91e-e1403229d286"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6841718692618436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    }
  ]
}